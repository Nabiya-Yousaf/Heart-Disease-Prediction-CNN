# -*- coding: utf-8 -*-
"""2312514-D-Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cBeWFGvued3mNDP8Pi1vUbr-zYvqRunD

Importing important libraries
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SimpleRNN
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input
from sklearn.metrics import confusion_matrix, f1_score, precision_score

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Nabiya-D/heart.csv')

# Display basic information about the dataset
print("Dataset shape:", df.shape)
print(df.info())
print(df.describe())

# Check for missing values
print("Missing values:", df.isnull().sum())


# Split the data into features and target
X = df.drop(columns=['target'])
y = df['target']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Reshape data for 1D CNN
X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

print("Data preparation completed.")

"""**Model 1**"""

from sklearn.metrics import confusion_matrix, f1_score, precision_score

# Build the 1D CNN model
model_cnn = Sequential([
    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),
    MaxPooling1D(pool_size=2),
    Conv1D(filters=64, kernel_size=3, activation='relu'),
    MaxPooling1D(pool_size=2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history_cnn = model_cnn.fit(X_train_cnn, y_train, epochs=20, validation_data=(X_test_cnn, y_test))

# Evaluate the model
cnn_loss, cnn_acc = model_cnn.evaluate(X_test_cnn, y_test)
y_pred_cnn = (model_cnn.predict(X_test_cnn) > 0.5).astype("int32")

# Compute F1 Score, Precision, and Confusion Matrix
cnn_f1 = f1_score(y_test, y_pred_cnn)
cnn_precision = precision_score(y_test, y_pred_cnn)
cnn_cm = confusion_matrix(y_test, y_pred_cnn)

print(f"1D CNN Model Accuracy: {cnn_acc*100:.2f}%")
print(f"1D CNN Model F1 Score: {cnn_f1:.2f}")
print(f"1D CNN Model Precision: {cnn_precision:.2f}")
print("1D CNN Confusion Matrix:\n", cnn_cm)

# Plot training & validation accuracy values
plt.plot(history_cnn.history['accuracy'])
plt.plot(history_cnn.history['val_accuracy'])
plt.title('1D CNN Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

"""**Model 2:**"""

# Define the input shape
input_shape = (X_train_cnn.shape[1], 1)

# Build the CNN model for feature extraction
inputs = Input(shape=input_shape)
x = Conv1D(filters=32, kernel_size=3, activation='relu')(inputs)
x = MaxPooling1D(pool_size=2)(x)
x = Flatten()(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)

# Create the model up to the feature extraction layer
model_cnn_feature_extractor = Model(inputs=inputs, outputs=x)

# Compile the model (optional if you are only using it for feature extraction)
model_cnn_feature_extractor.compile(optimizer='adam', loss='categorical_crossentropy')

# Now you can use it for feature extraction
X_train_features = model_cnn_feature_extractor.predict(X_train_cnn)
X_test_features = model_cnn_feature_extractor.predict(X_test_cnn)

# Build the MLP model
model_mlp = Sequential([
    Dense(128, activation='relu', input_shape=(X_train_features.shape[1],)),
    Dropout(0.5),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model_mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history_mlp = model_mlp.fit(X_train_features, y_train, epochs=20, validation_data=(X_test_features, y_test))

# Evaluate the model
mlp_loss, mlp_acc = model_mlp.evaluate(X_test_features, y_test)
y_pred_mlp = (model_mlp.predict(X_test_features) > 0.5).astype("int32")

# Compute F1 Score, Precision, and Confusion Matrix
mlp_f1 = f1_score(y_test, y_pred_mlp)
mlp_precision = precision_score(y_test, y_pred_mlp)
mlp_cm = confusion_matrix(y_test, y_pred_mlp)

print(f"MLP with CNN Features Model Accuracy: {mlp_acc*100:.2f}%")
print(f"MLP with CNN Features Model F1 Score: {mlp_f1:.2f}")
print(f"MLP with CNN Features Model Precision: {mlp_precision:.2f}")
print("MLP with CNN Features Confusion Matrix:\n", mlp_cm)

# Plot training & validation accuracy values
plt.plot(history_mlp.history['accuracy'])
plt.plot(history_mlp.history['val_accuracy'])
plt.title('MLP with CNN Features Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

"""**Model 3:**"""

# Build the CNN model for feature extraction
model_cnn_feature_extractor = Sequential([
    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),
    MaxPooling1D(pool_size=2),
    Conv1D(filters=64, kernel_size=3, activation='relu'),
    MaxPooling1D(pool_size=2),
    Flatten(),
    Dense(64, activation='relu'),  # Adjust the dense layer to match the required features
    Reshape((1, 64))  # Reshape output to be compatible with RNN input
])

# Extract features using the CNN model
X_train_features_rnn = model_cnn_feature_extractor.predict(X_train_cnn)
X_test_features_rnn = model_cnn_feature_extractor.predict(X_test_cnn)

# Build the RNN model using CNN features
model_rnn = Sequential([
    SimpleRNN(64, activation='relu', return_sequences=False, input_shape=(1, 64)),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history_rnn = model_rnn.fit(X_train_features_rnn, y_train, epochs=20, validation_data=(X_test_features_rnn, y_test))

# Evaluate the model
rnn_loss, rnn_acc = model_rnn.evaluate(X_test_features_rnn, y_test)
y_pred_rnn = (model_rnn.predict(X_test_features_rnn) > 0.5).astype("int32")

# Compute F1 Score, Precision, and Confusion Matrix
rnn_f1 = f1_score(y_test, y_pred_rnn)
rnn_precision = precision_score(y_test, y_pred_rnn)
rnn_cm = confusion_matrix(y_test, y_pred_rnn)

print(f"RNN with CNN Features Model Accuracy: {rnn_acc*100:.2f}%")
print(f"RNN with CNN Features Model F1 Score: {rnn_f1:.2f}")
print(f"RNN with CNN Features Model Precision: {rnn_precision:.2f}")
print("RNN with CNN Features Confusion Matrix:\n", rnn_cm)

# Plot training & validation accuracy values
plt.plot(history_rnn.history['accuracy'])
plt.plot(history_rnn.history['val_accuracy'])
plt.title('RNN with CNN Features Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

"""**Comparison and Visualization of Results**"""

# Comparison of accuracies, F1 scores, and precisions
models = ['1D CNN', 'MLP with CNN Features', 'RNN with CNN Features']
accuracies = [cnn_acc*100, mlp_acc*100, rnn_acc*100]
f1_scores = [cnn_f1, mlp_f1, rnn_f1]
precisions = [cnn_precision, mlp_precision, rnn_precision]

plt.figure(figsize=(25, 6))

# Plot accuracy comparison
plt.subplot(1, 3, 1)
plt.bar(models, accuracies, color='blue')
plt.ylim([0, 100])
plt.title('Model Accuracy Comparison')
plt.xlabel('Model')
plt.ylabel('Accuracy (%)')
plt.show()

# Plot F1 score comparison
plt.figure(figsize=(25, 6))
plt.subplot(1, 3, 2)
plt.bar(models, f1_scores, color='green')
plt.ylim([0, 1])
plt.title('Model F1 Score Comparison')
plt.xlabel('Model')
plt.ylabel('F1 Score')
plt.show()

# Plot precision comparison
plt.figure(figsize=(25, 6))
plt.subplot(1, 3, 3)
plt.bar(models, precisions, color='red')
plt.ylim([0, 1])
plt.title('Model Precision Comparison')
plt.xlabel('Model')
plt.ylabel('Precision')

plt.tight_layout()
plt.show()

"""**Visualizing the Confusion Matrices**"""

# Plot each confusion matrix as a separate image
# 1D CNN Confusion Matrix
plt.figure(figsize=(6, 5))
ConfusionMatrixDisplay(cnn_cm).plot(colorbar=False)
plt.title('1D CNN Confusion Matrix')
plt.show()

# MLP with CNN Features Confusion Matrix
plt.figure(figsize=(6, 5))
ConfusionMatrixDisplay(mlp_cm).plot(colorbar=False)
plt.title('MLP with CNN Features Confusion Matrix')
plt.show()

# RNN with CNN Features Confusion Matrix
plt.figure(figsize=(6, 5))
ConfusionMatrixDisplay(rnn_cm).plot(colorbar=False)
plt.title('RNN with CNN Features Confusion Matrix')
plt.show()